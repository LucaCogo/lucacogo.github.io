---
---

@inproceedings{cogo2025object,
bibtex_show={true},
title={Object Color Relighting with Progressively Decreasing Information},
booktitle={London Imaging Meeting},
volume={3128},
number={1},
pages={012007},
year={2025},
doi = {10.1088/1742-6596/3128/1/012007},
url = {https://iopscience.iop.org/article/10.1088/1742-6596/3128/1/012007/meta},
author={Cogo, Luca and Buzzelli, Marco and Bianco, Simone and Schettini, Raimondo},
keywords = {Spectral Imaging, Color Relighting},
abstract = {Object color relighting, the process of predicting an object's colorimetric values under new lighting conditions, is a significant challenge in computational imaging and graphics. This technique has important applications in augmented reality, digital heritage, and e-commerce. In this paper, we address object color relighting under progressively decreasing information settings, ranging from full spectral knowledge to tristimulus-only input. Our framework systematically compares physics-based rendering, spectral reconstruction, and colorimetric mapping techniques across varying data regimes. Experiments span five benchmark reflectance datasets and eleven standard illuminants, with relighting accuracy assessed via â–³E00 metric. Results indicate that third-order polynomial regressions give good results when trained with small datasets, while neural spectral reconstruction achieves superior performance with large-scale training. Spectral methods also exhibit higher robustness to illuminant variability, emphasizing the value of intermediate spectral estimation in practical relighting scenarios.},
preview = {cogo2025object.png},
pdf = {cogo2025object.pdf},
}

@inproceedings{buzzelli2025fair,
bibtex_show={true},
title = {On the fair use of the ColorChecker dataset for illuminant estimation},
booktitle={London Imaging Meeting},
volume={3128},
number={1},
pages={012014},
year={2025},
doi = {10.1088/1742-6596/3128/1/012014},
url = {https://iopscience.iop.org/article/10.1088/1742-6596/3128/1/012014/meta},
author={Buzzelli, Marco and Finlayson, Graham and Gijsenij, Arjan and Gehler, Peter and Drew, Mark and Shi, Lilong and Cogo, Luca and Bianco, Simone},
keywords = {Illuminant Estimation, Computational Color constancy},
abstract = {The ColorChecker dataset is the most widely used dataset for evaluating and benchmarking illuminant-estimation algorithms. Although it is distributed with a 3-fold cross-validation partitioning, no procedure is defined on how to use it. In order to permit a fair comparison between illuminant-estimation algorithms, in this short correspondence we define a fair comparison procedure, showing that illuminant-estimation errors of state-of-the-art algorithms have been underestimated by up to 33%. We also compute the lower error bounds that can be reached on this dataset, which demonstrates that the existing algorithms have not yet reached their maximum performance potential.},
preview = {buzzelli2025fair.png},
pdf = {buzzelli2025fair.pdf},
}


@article{cogo2025robust,
bibtex_show={true},
title = {Robust camera-independent color chart localization using YOLO},
journal = {Pattern Recognition Letters},
volume = {192},
pages = {51-58},
year = {2025},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2025.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0167865525001138},
author = {Luca Cogo and Marco Buzzelli and Simone Bianco and Raimondo Schettini},
keywords = {Object detection, Color target, Pose estimation},
abstract = {Accurate color information plays a critical role in numerous computer vision tasks, with the Macbeth ColorChecker being a widely used reference target due to its colorimetrically characterized color patches. However, automating the precise extraction of color information in complex scenes remains a challenge. In this paper, we propose a novel method for the automatic detection and accurate extraction of color information from Macbeth ColorCheckers in challenging environments. Our approach involves two distinct phases: (i) a chart localization step using a deep learning model to identify the presence of the ColorChecker, and (ii) a consensus-based pose estimation and color extraction phase that ensures precise localization and description of individual color patches. We rigorously evaluate our method using the widely adopted NUS and ColorChecker datasets. Comparative results against state-of-the-art methods show that our method outperforms the best solution in the state of the art achieving about 5% improvement on the ColorChecker dataset and about 17% on the NUS dataset. Furthermore, the design of our approach enables it to handle the presence of multiple ColorCheckers in complex scenes. Code will be made available after pubblication at: https://github.com/LucaCogo/ColorChartLocalization.},
preview = {cogo2025robust.jpg},
pdf = {cogo2025robust.pdf},
code = {https://github.com/LucaCogo/ColorChartLocalization}
}


@article{agarla2024rgbilluminant,
title = {RGB illuminant compensation using multi-spectral information},
journal = {XIX Color Conference},
year = {2024},
author = {Mirko Agarla and Simone Bianco and Marco Buzzelli and Luca Cogo and Ilaria Erba and Matteo Kolyszko and Raimondo Schettini and Simone Zini},
abstract = {Multispectral imaging is a technique that captures data across several bands of the light spectrum, in this contribute we report our research related to its application to illuminant estimation an correction in RGB domains. In particular, we present 1. a method that exploits multispectral imaging for illuminant estimation, and then applies illuminant correction in the raw RGB domain to achieve computational color constancy. 2. A method that combines the illuminant estimation in the RGB color and in the spectral domains, as a strategy to provide a refined estimation in the RGB color domain. 3. A method that recovers as accurately as possible the spectral information of both the image and the illuminant using Spectral Super Resolution techniques, and exploits a weighted spectral compensation technique that optimizes compensate for possible spectral to perform effective color correction.},
preview = {agarla2024rgbilluminant.png},
pdf = {agarla2024rgbilluminant.pdf}
}